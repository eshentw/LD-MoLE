name: qwen3_1.7b
model_name: "Qwen/Qwen3-1.7B"
use_hf_weights: True

# Model-specific configurations
pad_token_id: 151643  # Qwen3 specific pad token ID

# Debugging configurations
output_attentions: True

# Lora configurations
apply_lora: True
lora:
  lora_freeze: False # lora head
  router_freeze: False # router
  sparsegen_init: "kaiming" # Options: "kaiming", "dense" (λ≈0, many adapters), "sparse" (λ≈1, few adapters), "zeros"
  r: 8
  lora_alpha: 16
  lora_dropout: 0.1
  lora_nums: 8
  bias: "none"
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  modules_to_save: # If you want to train and save classifier or other modules
    - "score"
    # - "sparsegen"

  sparsegen_cfg:
    enabled: True
    init_strategy: "kaiming" # Options: "kaiming", "dense" (λ≈0, many adapters), "sparse" (λ≈1, few adapters), "zeros"
    input_sizes: [2048, 6144] # other: 2048, down: 6144
    hidden_sizes: 256